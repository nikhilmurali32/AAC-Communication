{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37882fc-385f-4941-83b9-84ca9575037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/nikhil/.local/lib/python3.10/site-packages (4.0.2)\n",
      "Requirement already satisfied: tqdm in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (2.6.0+cu118)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (4.13.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence_transformers) (9.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from sentence_transformers) (1.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (0.29.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/nikhil/.local/lib/python3.10/site-packages (from sentence_transformers) (4.50.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/nikhil/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\n",
      "Requirement already satisfied: filelock in /home/nikhil/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: requests in /home/nikhil/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/nikhil/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.1.48)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.87)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence_transformers) (2.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.89)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.86)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/nikhil/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.5.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nikhil/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/nikhil/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nikhil/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nikhil/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/nikhil/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nikhil/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nikhil/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikhil/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.25.0 in /home/nikhil/.local/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/nikhil/.local/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c71a54-3b41-499d-afd5-b5197e6261c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS index for RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████| 2317/2317 [00:20<00:00, 110.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Example Single Query Processing =====\n",
      "Getting response from Flan-T5...\n",
      "Retrieving relevant documents from RAG...\n",
      "Creating prompt for GPT-4o...\n",
      "Getting response from GPT-4o...\n",
      "Error calling GPT-4o API: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "----- Flan-T5 Response -----\n",
      "I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that.\n",
      "\n",
      "----- RAG Retrieved Documents -----\n",
      "Document 1 (Score: 0.77):\n",
      "Input: ASSISTANT: I found out my dog has cancer today\n",
      "Target: Oh no! Is it serious?\n",
      "\n",
      "Document 2 (Score: 0.74):\n",
      "Input: ASSISTANT: My dog has cancer.\n",
      "Target: I am sorry to hear that.  Unfortunately a lot of dog breeds have a high risk of cancer.  Is it treatable?\n",
      "\n",
      "Document 3 (Score: 0.67):\n",
      "Input: ASSISTANT: My dog has cancer. | ASSISTANT: I am sorry to hear that.  Unfortunately a lot of dog breeds have a high risk of cancer.  Is it treatable? | ASSISTANT: I guess not because the surgery didn't work so we have to put her down.\n",
      "Target: Oh my.  I have been in that situation before.  You have my sympathies.\n",
      "\n",
      "\n",
      "----- GPT-4o Response -----\n",
      "Error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-****\"  # Replace with your actual API key\n",
    "client = OpenAI()\n",
    "\n",
    "# Load your fine-tuned model\n",
    "finetuned_model_path = \"./flan-t5-empathy-final\"\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_path)\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "# Load your knowledge base data - this would be your empathy dataset or any related corpus\n",
    "# Here I'm assuming we'll use the training data as our knowledge base\n",
    "data_files = {\n",
    "    \"train\": \"empathy_new/empathy_train_new.csv\",\n",
    "    \"test\": \"empathy_new/empathy_test_new.csv\"\n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "# Class for RAG implementation\n",
    "class RAGSystem:\n",
    "    def __init__(self, knowledge_base: List[Dict], embedding_model: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the RAG system with a knowledge base and embedding model.\n",
    "        \n",
    "        Args:\n",
    "            knowledge_base: List of dictionaries with input_text and target_text\n",
    "            embedding_model: Name of the SentenceTransformer model to use\n",
    "        \"\"\"\n",
    "        self.knowledge_base = knowledge_base\n",
    "        self.embedding_model = SentenceTransformer(embedding_model)\n",
    "        \n",
    "        # Create FAISS index for fast similarity search\n",
    "        self._create_index()\n",
    "        \n",
    "    def _create_index(self):\n",
    "        \"\"\"Create a FAISS index from the knowledge base\"\"\"\n",
    "        print(\"Creating FAISS index for RAG...\")\n",
    "        # Extract texts for embedding\n",
    "        texts = [item[\"input_text\"] for item in self.knowledge_base]\n",
    "        \n",
    "        # Create embeddings\n",
    "        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        \n",
    "        # Build FAISS index\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)  # Inner product for cosine similarity\n",
    "        self.index.add(normalized_embeddings.astype(np.float32))\n",
    "        \n",
    "    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve the top_k most relevant documents for the query.\n",
    "        \n",
    "        Args:\n",
    "            query: The user query\n",
    "            top_k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents with scores\n",
    "        \"\"\"\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "        \n",
    "        # Search the index\n",
    "        scores, indices = self.index.search(\n",
    "            np.array([query_embedding]).astype(np.float32), \n",
    "            k=top_k\n",
    "        )\n",
    "        \n",
    "        # Return the retrieved documents with scores\n",
    "        retrieved_docs = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            retrieved_docs.append({\n",
    "                \"score\": float(score),\n",
    "                \"input_text\": self.knowledge_base[idx][\"input_text\"],\n",
    "                \"target_text\": self.knowledge_base[idx][\"target_text\"]\n",
    "            })\n",
    "            \n",
    "        return retrieved_docs\n",
    "\n",
    "# Function to get Flan-T5 response\n",
    "def get_flan_t5_response(model, tokenizer, query, device):\n",
    "    \"\"\"Generate response from Flan-T5 model\"\"\"\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return prediction\n",
    "\n",
    "# Function to get GPT-4o response\n",
    "def get_gpt4o_response(prompt):\n",
    "    \"\"\"Get response from GPT-4o using the OpenAI API\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling GPT-4o API: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Function to create prompt for GPT-4o using both Flan-T5 and RAG outputs\n",
    "def create_gpt4o_prompt(query, flan_t5_response, rag_documents):\n",
    "    \"\"\"Create a prompt for GPT-4o using both Flan-T5 and RAG results\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are assisting with generating an empathetic response to the following query:\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "I have two sources of information to help craft the response:\n",
    "\n",
    "1. OUTPUT FROM FINE-TUNED EMPATHY MODEL:\n",
    "{flan_t5_response}\n",
    "\n",
    "2. SIMILAR EXAMPLES FROM DATABASE:\n",
    "\"\"\"\n",
    "    \n",
    "    for i, doc in enumerate(rag_documents, 1):\n",
    "        prompt += f\"\"\"\n",
    "Example {i} (Similarity Score: {doc['score']:.2f}):\n",
    "- Situation: {doc['input_text']}\n",
    "- Empathetic Response: {doc['target_text']}\n",
    "\"\"\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "Please synthesize these sources to create a highly empathetic response that addresses the query directly.\n",
    "Your response should:\n",
    "1. Show understanding of the emotions and situation\n",
    "2. Validate their feelings\n",
    "3. Offer appropriate support or perspective\n",
    "4. Be natural and conversational in tone\n",
    "\n",
    "EMPATHETIC RESPONSE:\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Prepare the knowledge base for RAG\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"input_text\": \"At my sister's wedding, I wanted to say how proud I was of her.\",\n",
    "        \"target_text\": \"You looked absolutely stunning today. I’m so proud of you—it means the world to see you this happy.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in a loud cafeteria and need to ask for help finding a seat.\",\n",
    "        \"target_text\": \"Excuse me, can you help me find a spot to sit? It’s a bit too loud for me to navigate easily.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"During therapy, I want to talk about how I felt last weekend when no one included me.\",\n",
    "        \"target_text\": \"I felt left out last weekend when nobody reached out. It hurt more than I expected.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm excited to share my science fair project with my classmates.\",\n",
    "        \"target_text\": \"Hey everyone! I’ve been working hard on this—can’t wait to show you my volcano experiment!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone misunderstands my speech device output and thinks I’m being rude.\",\n",
    "        \"target_text\": \"I’m sorry if that came off the wrong way—sometimes my device doesn’t get my tone right, but I promise I meant it kindly.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"In a casual conversation when I want to joke with a friend about our shared obsession with pizza.\",\n",
    "        \"target_text\": \"If loving pizza was a crime, we’d be serving life sentences together!\"\n",
    "    },\n",
    "{\n",
    "        \"input_text\": \"I want to tell my friend I missed them at school today.\",\n",
    "        \"target_text\": \"School wasn’t the same without you today. I missed your jokes and your energy!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm nervous about presenting in front of the class.\",\n",
    "        \"target_text\": \"I’m a little nervous, but I’ve prepared a lot. I’m ready to give it my best shot!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone new joins our group and I want to welcome them.\",\n",
    "        \"target_text\": \"Hey! I’m really glad you’re here. Can’t wait to get to know you better!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in pain but can't express it quickly.\",\n",
    "        \"target_text\": \"I’m hurting right now. Please give me a moment and help me feel more comfortable.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to cheer someone up after they failed a test.\",\n",
    "        \"target_text\": \"One bad test doesn’t define you. You’ve got this, and I believe in you!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"During dinner, I want to tell my family how my day went.\",\n",
    "        \"target_text\": \"Today was a mix of fun and stress, but I learned something new and made it through!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When my device is glitching and I need extra time.\",\n",
    "        \"target_text\": \"Sorry, my speech device is acting up. Can you give me a second to fix it?\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"At the doctor's office, when they ask how I've been feeling.\",\n",
    "        \"target_text\": \"I’ve been feeling a bit off lately. Some days are harder than others.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to express joy after winning a game.\",\n",
    "        \"target_text\": \"Yes! That was awesome. I feel like a champion right now!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When a friend shares something personal and I want to respond with empathy.\",\n",
    "        \"target_text\": \"Thank you for sharing that. I’m here for you no matter what.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm overstimulated in a busy environment and need a break.\",\n",
    "        \"target_text\": \"It’s too much for me right now. I need a quiet space to recharge.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to tell someone that I like them in a playful way.\",\n",
    "        \"target_text\": \"So… I kind of think you’re really cool. Just putting that out there!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone says something kind to me and I want to respond meaningfully.\",\n",
    "        \"target_text\": \"That really means a lot to me. Thank you for being so thoughtful.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to explain why I use a speech device.\",\n",
    "        \"target_text\": \"I use this device to help me express myself. It’s my voice, just delivered differently.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone interrupts me before I finish my sentence.\",\n",
    "        \"target_text\": \"Please wait a second—I’m not done talking yet. I want to share my full thought.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I feel left out of a group activity.\",\n",
    "        \"target_text\": \"I noticed I wasn’t included, and it made me feel invisible. I want to be part of things too.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to start a conversation at lunch.\",\n",
    "        \"target_text\": \"What’s the best thing you’ve eaten this week? Let’s trade snack stories!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to talk about my favorite hobby—drawing.\",\n",
    "        \"target_text\": \"I love drawing! It helps me show how I feel when words don’t quite fit.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I need to say 'no' without sounding upset.\",\n",
    "        \"target_text\": \"No, thank you. That doesn’t work for me right now, but I appreciate you asking.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to express gratitude to my teacher for supporting me.\",\n",
    "        \"target_text\": \"Thank you for always encouraging me. You help me grow more than you know.\"\n",
    "    },\n",
    "{\n",
    "        \"input_text\": \"When I want to say I'm tired without sounding negative.\",\n",
    "        \"target_text\": \"I’m feeling low on energy right now. I think I just need a little rest.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to join a group conversation but don’t know how to start.\",\n",
    "        \"target_text\": \"Hey, can I join in? I’d love to be part of what you’re talking about.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone makes fun of how I talk or use my device.\",\n",
    "        \"target_text\": \"This is how I communicate. It deserves just as much respect as any voice.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I’m happy and want to share the moment with someone.\",\n",
    "        \"target_text\": \"This just made my whole day! I wish I could bottle this feeling forever.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to ask someone for help opening something.\",\n",
    "        \"target_text\": \"Can you help me open this, please? It’s being a bit stubborn today.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say I'm okay, even if I don’t look it.\",\n",
    "        \"target_text\": \"I know I might seem off, but I’m actually okay right now—just processing quietly.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to share how music helps me regulate emotions.\",\n",
    "        \"target_text\": \"Music helps me feel calmer when things get overwhelming. It’s like a reset button.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to clarify something I said earlier.\",\n",
    "        \"target_text\": \"I think what I said might’ve been confusing—let me explain it a little better.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I need time to think before responding.\",\n",
    "        \"target_text\": \"Give me a second—I’m still thinking it through. I’ll respond in a moment.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone is being overly helpful and I want space.\",\n",
    "        \"target_text\": \"I appreciate you helping, but I’d like to try this myself first.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to tell a joke to lighten the mood.\",\n",
    "        \"target_text\": \"Why don’t skeletons fight each other? They don’t have the guts!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say I’m proud of myself after a hard task.\",\n",
    "        \"target_text\": \"That was tough, but I did it. I’m proud of myself for sticking with it!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say 'I love you' in a meaningful way.\",\n",
    "        \"target_text\": \"You make me feel safe and seen—I love you with my whole heart.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I need to leave early from an event because I'm overwhelmed.\",\n",
    "        \"target_text\": \"This has been fun, but I need to step away now. I’m starting to feel overwhelmed.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to request a break during a task.\",\n",
    "        \"target_text\": \"Can we take a quick break? I’ll be able to focus better after that.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone is talking too fast and I can’t follow.\",\n",
    "        \"target_text\": \"Could you please slow down a bit? I want to make sure I understand you.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to express interest in someone’s story.\",\n",
    "        \"target_text\": \"That sounds really interesting! Tell me more—I’m all ears.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say I don’t know the answer but want to try.\",\n",
    "        \"target_text\": \"I’m not sure right now, but I want to give it a try!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to explain that I need visual support.\",\n",
    "        \"target_text\": \"It helps me a lot when things are shown visually—can you write or draw it out?\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone praises me and I want to receive it gracefully.\",\n",
    "        \"target_text\": \"Thank you! I’ve been working really hard on that—I’m glad it shows.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for item in dataset[\"train\"]:\n",
    "    knowledge_base.append({\n",
    "        \"input_text\": str(item[\"input_text\"]) if item[\"input_text\"] is not None else \"\",\n",
    "        \"target_text\": str(item[\"target_text\"]) if item[\"target_text\"] is not None else \"\"\n",
    "    })\n",
    "\n",
    "# Initialize the RAG system\n",
    "rag_system = RAGSystem(knowledge_base)\n",
    "\n",
    "# Main function to process a query through the entire pipeline\n",
    "def process_query(query):\n",
    "    \"\"\"Process a query through Flan-T5, RAG, and GPT-4o\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Get response from fine-tuned Flan-T5 model\n",
    "    print(\"Getting response from Flan-T5...\")\n",
    "    flan_t5_response = get_flan_t5_response(finetuned_model, finetuned_tokenizer, query, device)\n",
    "    results[\"flan_t5_response\"] = flan_t5_response\n",
    "    \n",
    "    # Step 2: Get relevant documents from RAG\n",
    "    print(\"Retrieving relevant documents from RAG...\")\n",
    "    rag_documents = rag_system.retrieve(query, top_k=3)\n",
    "    results[\"rag_documents\"] = rag_documents\n",
    "    \n",
    "    # Step 3: Create prompt for GPT-4o\n",
    "    print(\"Creating prompt for GPT-4o...\")\n",
    "    gpt4o_prompt = create_gpt4o_prompt(query, flan_t5_response, rag_documents)\n",
    "    results[\"gpt4o_prompt\"] = gpt4o_prompt\n",
    "    \n",
    "    # Step 4: Get response from GPT-4o\n",
    "    print(\"Getting response from GPT-4o...\")\n",
    "    gpt4o_response = get_gpt4o_response(gpt4o_prompt)\n",
    "    results[\"gpt4o_response\"] = gpt4o_response\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to evaluate on test set\n",
    "def evaluate_pipeline(test_dataset, num_samples=None):\n",
    "    \"\"\"Evaluate the pipeline on the test dataset\"\"\"\n",
    "    # Get test queries\n",
    "    test_queries = [str(x) if x is not None else \"\" for x in test_dataset[\"test\"][\"input_text\"]]\n",
    "    reference_responses = [str(x) if x is not None else \"\" for x in test_dataset[\"test\"][\"target_text\"]]\n",
    "    \n",
    "    # Limit number of samples if specified\n",
    "    if num_samples:\n",
    "        test_queries = test_queries[:num_samples]\n",
    "        reference_responses = reference_responses[:num_samples]\n",
    "    \n",
    "    results = []\n",
    "    for i, query in enumerate(tqdm(test_queries, desc=\"Evaluating pipeline\")):\n",
    "        print(f\"\\nProcessing test query {i+1}/{len(test_queries)}\")\n",
    "        result = process_query(query)\n",
    "        \n",
    "        # Add reference response\n",
    "        result[\"reference_response\"] = reference_responses[i]\n",
    "        result[\"query\"] = query\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Save results incrementally\n",
    "        with open(f\"pipeline_results_{i+1}.json\", \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "    \n",
    "    # Save all results\n",
    "    with open(\"pipeline_results_all.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n===== Example Single Query Processing =====\")\n",
    "    # Process a single example\n",
    "    example_query = \"I just found out my dog has cancer and I don't know how I'm going to cope with this news.\"\n",
    "    results = process_query(example_query)\n",
    "    \n",
    "    print(\"\\n----- Flan-T5 Response -----\")\n",
    "    print(results[\"flan_t5_response\"])\n",
    "    \n",
    "    print(\"\\n----- RAG Retrieved Documents -----\")\n",
    "    for i, doc in enumerate(results[\"rag_documents\"], 1):\n",
    "        print(f\"Document {i} (Score: {doc['score']:.2f}):\")\n",
    "        print(f\"Input: {doc['input_text']}\")\n",
    "        print(f\"Target: {doc['target_text']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n----- GPT-4o Response -----\")\n",
    "    print(results[\"gpt4o_response\"])\n",
    "    \n",
    "    # Uncomment to evaluate on test set (be mindful of API costs!)\n",
    "    # print(\"\\n===== Evaluating on Test Set =====\")\n",
    "    # evaluate_pipeline(dataset, num_samples=5)  # Limit to 5 samples to avoid high API costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8828903f-618c-473c-b8b0-bf4fd2f234ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3250 samples out of 10834 total samples (30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nikhil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/nikhil/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nikhil/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building retrieval index from knowledge base...\n",
      "Creating embeddings for knowledge base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 91.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from fine-tuned model with RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3250/3250 [14:57<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: No existing fine-tuned predictions found at finetuned_predictions.txt\n",
      "Will only calculate metrics for RAG-enhanced model\n",
      "\n",
      "Fine-tuned Model with RAG Metrics:\n",
      "BLEU Score: 0.0079\n",
      "METEOR Score: 0.0788\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 375\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrag_bleu[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETEOR Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrag_meteor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-1 F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrag_rouge\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrouge1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241m.\u001b[39mfmeasure\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrag_diversity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocabulary_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType-Token Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrag_diversity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_token_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load your test dataset\n",
    "data_files = {\"test\": \"empathy_new/empathy_test_new.csv\"}\n",
    "test_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "# Take only 30% of the test dataset\n",
    "test_data = test_dataset[\"test\"]\n",
    "dataset_size = len(test_data)\n",
    "subset_size = int(dataset_size * 0.3)  # 30% of the dataset\n",
    "indices = np.random.choice(dataset_size, subset_size, replace=False)\n",
    "\n",
    "# Create a subset of the test dataset\n",
    "subset_input_texts = [str(test_data[\"input_text\"][i]) if test_data[\"input_text\"][i] is not None else \"\" for i in indices]\n",
    "subset_reference_texts = [str(test_data[\"target_text\"][i]) if test_data[\"target_text\"][i] is not None else \"\" for i in indices]\n",
    "\n",
    "print(f\"Using {subset_size} samples out of {dataset_size} total samples (30%)\")\n",
    "\n",
    "# Load metrics\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# Load your fine-tuned model\n",
    "finetuned_model_path = \"./flan-t5-empathy-final\"\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_path)\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "# Load sentence transformer for embeddings\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentence_model = sentence_model.to(device)\n",
    "\n",
    "# Define the provided knowledge base\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"input_text\": \"At my sister's wedding, I wanted to say how proud I was of her.\",\n",
    "        \"target_text\": \"You looked absolutely stunning today. I'm so proud of you—it means the world to see you this happy.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in a loud cafeteria and need to ask for help finding a seat.\",\n",
    "        \"target_text\": \"Excuse me, can you help me find a spot to sit? It's a bit too loud for me to navigate easily.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"During therapy, I want to talk about how I felt last weekend when no one included me.\",\n",
    "        \"target_text\": \"I felt left out last weekend when nobody reached out. It hurt more than I expected.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm excited to share my science fair project with my classmates.\",\n",
    "        \"target_text\": \"Hey everyone! I've been working hard on this—can't wait to show you my volcano experiment!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone misunderstands my speech device output and thinks I'm being rude.\",\n",
    "        \"target_text\": \"I'm sorry if that came off the wrong way—sometimes my device doesn't get my tone right, but I promise I meant it kindly.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"In a casual conversation when I want to joke with a friend about our shared obsession with pizza.\",\n",
    "        \"target_text\": \"If loving pizza was a crime, we'd be serving life sentences together!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to tell my friend I missed them at school today.\",\n",
    "        \"target_text\": \"School wasn't the same without you today. I missed your jokes and your energy!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm nervous about presenting in front of the class.\",\n",
    "        \"target_text\": \"I'm a little nervous, but I've prepared a lot. I'm ready to give it my best shot!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone new joins our group and I want to welcome them.\",\n",
    "        \"target_text\": \"Hey! I'm really glad you're here. Can't wait to get to know you better!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in pain but can't express it quickly.\",\n",
    "        \"target_text\": \"I'm hurting right now. Please give me a moment and help me feel more comfortable.\"\n",
    "    },\n",
    "  {\n",
    "        \"input_text\": \"At my sister's wedding, I wanted to say how proud I was of her.\",\n",
    "        \"target_text\": \"You looked absolutely stunning today. I'm so proud of you—it means the world to see you this happy.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in a loud cafeteria and need to ask for help finding a seat.\",\n",
    "        \"target_text\": \"Excuse me, can you help me find a spot to sit? It's a bit too loud for me to navigate easily.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"During therapy, I want to talk about how I felt last weekend when no one included me.\",\n",
    "        \"target_text\": \"I felt left out last weekend when nobody reached out. It hurt more than I expected.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm excited to share my science fair project with my classmates.\",\n",
    "        \"target_text\": \"Hey everyone! I've been working hard on this—can't wait to show you my volcano experiment!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone misunderstands my speech device output and thinks I'm being rude.\",\n",
    "        \"target_text\": \"I'm sorry if that came off the wrong way—sometimes my device doesn't get my tone right, but I promise I meant it kindly.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"In a casual conversation when I want to joke with a friend about our shared obsession with pizza.\",\n",
    "        \"target_text\": \"If loving pizza was a crime, we'd be serving life sentences together!\"\n",
    "    }, {\n",
    "        \"input_text\": \"I want to tell my friend I missed them at school today.\",\n",
    "        \"target_text\": \"School wasn't the same without you today. I missed your jokes and your energy!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I'm nervous about presenting in front of the class.\",\n",
    "        \"target_text\": \"I'm a little nervous, but I've prepared a lot. I'm ready to give it my best shot!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone new joins our group and I want to welcome them.\",\n",
    "        \"target_text\": \"Hey! I'm really glad you're here. Can't wait to get to know you better!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm in pain but can't express it quickly.\",\n",
    "        \"target_text\": \"I'm hurting right now. Please give me a moment and help me feel more comfortable.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to cheer someone up after they failed a test.\",\n",
    "        \"target_text\": \"One bad test doesn't define you. You've got this, and I believe in you!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"During dinner, I want to tell my family how my day went.\",\n",
    "        \"target_text\": \"Today was a mix of fun and stress, but I learned something new and made it through!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When my device is glitching and I need extra time.\",\n",
    "        \"target_text\": \"Sorry, my speech device is acting up. Can you give me a second to fix it?\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"At the doctor's office, when they ask how I've been feeling.\",\n",
    "        \"target_text\": \"I've been feeling a bit off lately. Some days are harder than others.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to express joy after winning a game.\",\n",
    "        \"target_text\": \"Yes! That was awesome. I feel like a champion right now!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When a friend shares something personal and I want to respond with empathy.\",\n",
    "        \"target_text\": \"Thank you for sharing that. I'm here for you no matter what.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm overstimulated in a busy environment and need a break.\",\n",
    "        \"target_text\": \"It's too much for me right now. I need a quiet space to recharge.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to tell someone that I like them in a playful way.\",\n",
    "        \"target_text\": \"So… I kind of think you're really cool. Just putting that out there!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone says something kind to me and I want to respond meaningfully.\",\n",
    "        \"target_text\": \"That really means a lot to me. Thank you for being so thoughtful.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to explain why I use a speech device.\",\n",
    "        \"target_text\": \"I use this device to help me express myself. It's my voice, just delivered differently.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone interrupts me before I finish my sentence.\",\n",
    "        \"target_text\": \"Please wait a second—I'm not done talking yet. I want to share my full thought.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I feel left out of a group activity.\",\n",
    "        \"target_text\": \"I noticed I wasn't included, and it made me feel invisible. I want to be part of things too.\"\n",
    "    },{\n",
    "        \"input_text\": \"When I want to start a conversation at lunch.\",\n",
    "        \"target_text\": \"What's the best thing you've eaten this week? Let's trade snack stories!\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to talk about my favorite hobby—drawing.\",\n",
    "        \"target_text\": \"I love drawing! It helps me show how I feel when words don't quite fit.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I need to say 'no' without sounding upset.\",\n",
    "        \"target_text\": \"No, thank you. That doesn't work for me right now, but I appreciate you asking.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"I want to express gratitude to my teacher for supporting me.\",\n",
    "        \"target_text\": \"Thank you for always encouraging me. You help me grow more than you know.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say I'm tired without sounding negative.\",\n",
    "        \"target_text\": \"I'm feeling low on energy right now. I think I just need a little rest.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to join a group conversation but don't know how to start.\",\n",
    "        \"target_text\": \"Hey, can I join in? I'd love to be part of what you're talking about.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When someone makes fun of how I talk or use my device.\",\n",
    "        \"target_text\": \"This is how I communicate. It deserves just as much respect as any voice.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I'm happy and want to share the moment with someone.\",\n",
    "        \"target_text\": \"This just made my whole day! I wish I could bottle this feeling forever.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to ask someone for help opening something.\",\n",
    "        \"target_text\": \"Can you help me open this, please? It's being a bit stubborn today.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to say I'm okay, even if I don't look it.\",\n",
    "        \"target_text\": \"I know I might seem off, but I'm actually okay right now—just processing quietly.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to share how music helps me regulate emotions.\",\n",
    "        \"target_text\": \"Music helps me feel calmer when things get overwhelming. It's like a reset button.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"When I want to clarify something I said earlier.\",\n",
    "        \"target_text\": \"I think what I said might've been confusing—let me explain it a little better.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to build the retrieval index from the knowledge base\n",
    "def build_retrieval_index_from_kb(kb):\n",
    "    \"\"\"Build a FAISS index for retrieval from the knowledge base\"\"\"\n",
    "    texts = [item[\"input_text\"] for item in kb]\n",
    "    responses = [item[\"target_text\"] for item in kb]\n",
    "    \n",
    "    print(\"Creating embeddings for knowledge base...\")\n",
    "    embeddings = sentence_model.encode(texts, show_progress_bar=True, convert_to_tensor=True)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    \n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    return index, texts, responses\n",
    "\n",
    "# Define retrieval function\n",
    "def retrieve_similar_examples(query, index, texts, responses, k=3):\n",
    "    \"\"\"Retrieve k most similar examples from the index\"\"\"\n",
    "    query_embedding = sentence_model.encode([query], convert_to_tensor=True).cpu().numpy()\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    retrieved_texts = [texts[idx] for idx in indices[0]]\n",
    "    retrieved_responses = [responses[idx] for idx in indices[0]]\n",
    "    \n",
    "    return retrieved_texts, retrieved_responses\n",
    "\n",
    "# Generate predictions with RAG function\n",
    "def generate_predictions_with_rag(model, tokenizer, texts, index, kb_texts, kb_responses, device):\n",
    "    \"\"\"Generate predictions with RAG\"\"\"\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    \n",
    "    for text in tqdm(texts):\n",
    "        # Retrieve similar examples\n",
    "        retrieved_texts, retrieved_responses = retrieve_similar_examples(text, index, kb_texts, kb_responses)\n",
    "        \n",
    "        # Create an augmented prompt\n",
    "        augmented_prompt = text + \"\\n\\nSimilar situations and responses:\\n\"\n",
    "        for i, (rt, rr) in enumerate(zip(retrieved_texts, retrieved_responses)):\n",
    "            augmented_prompt += f\"Situation {i+1}: {rt}\\nResponse {i+1}: {rr}\\n\\n\"\n",
    "        \n",
    "        augmented_prompt += \"Generate an empathetic response to the original situation:\"\n",
    "        \n",
    "        inputs = tokenizer(augmented_prompt, return_tensors=\"pt\", truncation=True, max_length=768).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Utility function for diversity metrics\n",
    "def calculate_diversity_metrics(predictions):\n",
    "    \"\"\"Calculate lexical diversity metrics\"\"\"\n",
    "    vocab_size = set()\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for pred in predictions:\n",
    "        tokens = pred.split()\n",
    "        vocab_size.update(tokens)\n",
    "        total_tokens += len(tokens)\n",
    "    \n",
    "    # TTR (Type-Token Ratio)\n",
    "    ttr = len(vocab_size) / total_tokens if total_tokens > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"vocabulary_size\": len(vocab_size),\n",
    "        \"type_token_ratio\": ttr\n",
    "    }\n",
    "\n",
    "# Function to load existing predictions\n",
    "def load_existing_predictions(file_path, indices=None):\n",
    "    \"\"\"Load predictions from a file based on indices\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File {file_path} not found. Returning empty list.\")\n",
    "        return []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        all_predictions = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    if indices is not None and len(all_predictions) >= max(indices) + 1:\n",
    "        return [all_predictions[i] for i in indices]\n",
    "    else:\n",
    "        print(f\"Warning: Indices out of range or file format not as expected. Using all predictions.\")\n",
    "        return all_predictions[:len(indices)] if indices is not None else all_predictions\n",
    "\n",
    "# Build retrieval index from the knowledge base\n",
    "print(\"Building retrieval index from knowledge base...\")\n",
    "index, kb_texts, kb_responses = build_retrieval_index_from_kb(knowledge_base)\n",
    "\n",
    "# Generate predictions with the fine-tuned model enhanced with RAG\n",
    "print(\"Generating predictions from fine-tuned model with RAG...\")\n",
    "rag_predictions = generate_predictions_with_rag(finetuned_model, finetuned_tokenizer, subset_input_texts, \n",
    "                                              index, kb_texts, kb_responses, device)\n",
    "\n",
    "# Format references for BLEU\n",
    "references_for_bleu = [[ref] for ref in subset_reference_texts]\n",
    "\n",
    "# Try to load existing fine-tuned model predictions\n",
    "# Update the file path to where your fine-tuned predictions are stored\n",
    "finetuned_predictions_path = \"finetuned_predictions.txt\"\n",
    "if os.path.exists(finetuned_predictions_path):\n",
    "    print(f\"Loading existing fine-tuned predictions from {finetuned_predictions_path}\")\n",
    "    finetuned_predictions = load_existing_predictions(finetuned_predictions_path, indices)\n",
    "    \n",
    "    # Check if we have enough predictions\n",
    "    if len(finetuned_predictions) < len(subset_input_texts):\n",
    "        print(f\"Warning: Only found {len(finetuned_predictions)} predictions, but need {len(subset_input_texts)}.\")\n",
    "        print(\"Make sure your fine-tuned predictions file has one prediction per line.\")\n",
    "        \n",
    "    # Calculate metrics for fine-tuned model without RAG (if available)\n",
    "    if len(finetuned_predictions) == len(subset_input_texts):\n",
    "        finetuned_bleu = bleu_metric.compute(predictions=finetuned_predictions, references=references_for_bleu)\n",
    "        finetuned_meteor = meteor_metric.compute(predictions=finetuned_predictions, references=subset_reference_texts)\n",
    "        finetuned_rouge = rouge_metric.compute(predictions=finetuned_predictions, references=subset_reference_texts)\n",
    "        finetuned_diversity = calculate_diversity_metrics(finetuned_predictions)\n",
    "        \n",
    "        print(\"\\nFine-tuned Model Metrics (without RAG):\")\n",
    "        print(f\"BLEU Score: {finetuned_bleu['bleu']:.4f}\")\n",
    "        print(f\"METEOR Score: {finetuned_meteor['meteor']:.4f}\")\n",
    "        print(f\"ROUGE-1 F1: {finetuned_rouge['rouge1'].mid.fmeasure:.4f}\")\n",
    "        print(f\"Vocabulary Size: {finetuned_diversity['vocabulary_size']}\")\n",
    "        print(f\"Type-Token Ratio: {finetuned_diversity['type_token_ratio']:.4f}\")\n",
    "else:\n",
    "    print(f\"Note: No existing fine-tuned predictions found at {finetuned_predictions_path}\")\n",
    "    print(\"Will only calculate metrics for RAG-enhanced model\")\n",
    "\n",
    "# Calculate metrics for fine-tuned model with RAG\n",
    "rag_bleu = bleu_metric.compute(predictions=rag_predictions, references=references_for_bleu)\n",
    "rag_meteor = meteor_metric.compute(predictions=rag_predictions, references=subset_reference_texts)\n",
    "rag_rouge = rouge_metric.compute(predictions=rag_predictions, references=subset_reference_texts)\n",
    "rag_diversity = calculate_diversity_metrics(rag_predictions)\n",
    "\n",
    "# Print RAG model metrics\n",
    "print(\"\\nFine-tuned Model with RAG Metrics:\")\n",
    "print(f\"BLEU Score: {rag_bleu['bleu']:.4f}\")\n",
    "print(f\"METEOR Score: {rag_meteor['meteor']:.4f}\")\n",
    "print(f\"ROUGE-1 F1: {rag_rouge['rouge1'].mid.fmeasure:.4f}\")\n",
    "print(f\"Vocabulary Size: {rag_diversity['vocabulary_size']}\")\n",
    "print(f\"Type-Token Ratio: {rag_diversity['type_token_ratio']:.4f}\")\n",
    "\n",
    "# Save RAG predictions\n",
    "with open(\"rag_predictions_30pct_subset.txt\", \"w\") as f:\n",
    "    for pred in rag_predictions:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "# Save comparison samples if fine-tuned predictions are available\n",
    "if os.path.exists(finetuned_predictions_path) and len(finetuned_predictions) == len(subset_input_texts):\n",
    "    with open(\"rag_comparison_30pct_subset.txt\", \"w\") as f:\n",
    "        f.write(f\"EVALUATION ON 30% SUBSET ({subset_size} SAMPLES)\\n\\n\")\n",
    "        for i in range(len(subset_input_texts)):\n",
    "            f.write(f\"Input: {subset_input_texts[i]}\\n\")\n",
    "            f.write(f\"Reference: {subset_reference_texts[i]}\\n\")\n",
    "            f.write(f\"Fine-tuned: {finetuned_predictions[i]}\\n\")\n",
    "            f.write(f\"RAG: {rag_predictions[i]}\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "    print(f\"\\nComparison results saved to 'rag_comparison_30pct_subset.txt'\")\n",
    "else:\n",
    "    with open(\"rag_samples_30pct_subset.txt\", \"w\") as f:\n",
    "        f.write(f\"RAG EVALUATION ON 30% SUBSET ({subset_size} SAMPLES)\\n\\n\")\n",
    "        for i in range(len(subset_input_texts)):\n",
    "            f.write(f\"Input: {subset_input_texts[i]}\\n\")\n",
    "            f.write(f\"Reference: {subset_reference_texts[i]}\\n\")\n",
    "            f.write(f\"RAG: {rag_predictions[i]}\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "    print(f\"\\nRAG samples saved to 'rag_samples_30pct_subset.txt'\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "346a4cc3-3262-407e-b01d-6e50d54eed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.1224\n",
      "ROUGE-2: 0.0130\n",
      "ROUGE-L: 0.1141\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROUGE-1: {rag_rouge['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {rag_rouge['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {rag_rouge['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62acbb77-ef54-4c7d-a6a1-8ddf5cbaad77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
